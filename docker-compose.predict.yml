version: "3.5"
services:
  mongo:
    container_name: mongo
    image: mongo:4.4
    command: --nojournal
    networks:
      - fiware
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_ROOT_USERNAME=root
      - MONGO_INITDB_ROOT_PASSWORD=example
    healthcheck:
      test: |
        host=`hostname --ip-address || echo '127.0.0.1'`; 
        mongo --quiet $host/test --eval 'quit(db.runCommand({ ping: 1 }).ok ? 0 : 2)' && echo 0 || echo 1
  orion:
    container_name: orion
    image: fiware/orion:3.8.1
    links:
      - mongo
    ports:
      - "1026:1026"
    command: -dbhost mongo -dbuser root -dbpwd example #-logLevel DEBUG
    healthcheck:
      test: curl --fail -s http://orion:1026/version || exit 1
    networks:
      - fiware
  web:
    container_name: web
    build:
      context: ./web
    ports:
      - "3000:3000"
    depends_on:
      - orion
    networks:
      - fiware
    command: bash -c "sh /entities/awaitForOrion.sh && sh /entities/createPredictionEntities.sh && sh /entities/subscribeReqPredictionTicket.sh && sh /entities/subscribeResPredictionTicket.sh && npm start"    
    environment:
      - URL_CB=http://orion:1026/v2/entities/ReqTicketPrediction1/attrs
      - MONGO_URI=mongodb://root:example@mongo:27017/sth_test?authSource=admin
    volumes:
      - ./entities:/entities

  spark-submit-predict:
    build:
      context: ./docker
    container_name: spark-submit-predict
    # depends_on:
    #   - spark-master
    #   - spark-worker-1
    ports:
      - "4041:4040"
    environment:
      - "SPARK_MASTER=spark://spark-master-train:7077"
      - "constraint:node==spark-submit"
      - "SERVER=proxy"
      - "HOST_CB=orion"
      - "MLFLOW_HOST=mlflow-server"
      - "MODEL_VERSION=1"
    command: bash -c "sleep 15; sh /prediction-job/run-spark-jobs-predict.sh"
    networks:
      - fiware
    volumes:
      - ./prediction-job:/prediction-job

#   spark-master:
#     image: bde2020/spark-master:2.4.5-hadoop2.7
#     container_name: spark-master
#     ports:
#       - "8082:8080"
#       - "7078:7077"
#       - "9002:9001"
#     environment:
#       - INIT_DAEMON_STEP=setup_spark
#       - "constraint:node==spark-master"
#     networks:
#          - fiware
#     command: bash -c "sleep 12 && sh /prediction-job/run-spark-jobs.sh"
#     volumes:
#       - ./prediction-job:/prediction-job

#   spark-worker-1:
#     image: bde2020/spark-worker:2.4.5-hadoop2.7
#     container_name: spark-worker-1
#     depends_on:
#       - spark-master
#     ports:
#       - "8083:8081"
#     environment:
#       - "SPARK_MASTER=spark://spark-master:7077"
#       - "constraint:node==spark-master"
#     networks:
#         - fiware

networks:
  fiware:
